<!DOCTYPE html>
<html lang="en">

    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">

        
        <title>Ordinary least squares, ℓ² (ridge), and ℓ¹ (lasso) linear regressions - Maxwell Forbes</title>
        
        <meta content="Ordinary least squares, ℓ² (ridge), and ℓ¹ (lasso) linear regressions - Maxwell Forbes" property="title"/>
        <meta content="Ordinary least squares, ℓ² (ridge), and ℓ¹ (lasso) linear regressions - Maxwell Forbes" property="og:title"/>
        <meta name="twitter:title" content="Ordinary least squares, ℓ² (ridge), and ℓ¹ (lasso) linear regressions - Maxwell Forbes"/>

        <link rel="shortcut icon" type="image/svg+xml" href="/assets/img/favicon.svg">
<link rel="shortcut icon" type="image/png" href="/assets/img/favicon.png">

<link href='/assets/css/tachyons.min.css' rel='stylesheet' type='text/css'/>
<link href='/assets/css/style.css' rel='stylesheet' type='text/css'/>
<link href='/assets/css/syntax/prism.default.css' rel='stylesheet' type='text/css'/>
<link href='/assets/css/syntax/prism.okaidia.css' rel='stylesheet' type='text/css'/>


<meta name='twitter:site' content='@maxforbes'/>

    
    <meta content='https://maxwellforbes.com/posts/regression-math/' property='og:url'/>
    
    
        
        <meta content="Preface Permalink to “Preface” #I wrote this in 2017, and am posting it now in 2021. I was surprised how difficult it..." property='og:description'/>
        <meta name='twitter:description' content="Preface Permalink to “Preface” #I wrote this in 2017, and am posting it now in 2021. I was surprised how difficult it..."/>
    
    <meta content="article" property="og:type"/>





    </head>

    <body class="lh-copy pa0 f5 f4-ns sans-serif">
        <script>
            /**
 * Logic:
 * (1) page load
 *   - if manual pref storage is set (light, dark, vaporwave), respect that
 *   - else, if matchMedia() set to dark, do that
 *   - else, light mode
 *
 * (2) setting pref
 *   - if new pref is same as matchMedia(), then clear storage.
 *   - if new pref differs from matchMedia(), set in storage.
 *   - Always set new pref. (Just call (1))
 */

const allowedSchemes = ['light', 'dark', 'vaporwave'];
let curScheme = null;

// theme (str) can be 'dark' or 'light'
function systemWants(theme) {
    return window.matchMedia != null && window.matchMedia('(prefers-color-scheme: ' + theme + ')').matches;
}

function setColorScheme() {
    // default is light
    let desired = "light";

    // if manual pref storage is set (light, dark, vaporwave), respect that
    let userPref = window.localStorage.getItem('color-scheme');
    if (userPref != null && allowedSchemes.indexOf(userPref) != -1) {
        desired = userPref;
    } else if (systemWants("dark")) {
        // or, if matchMedia() set to dark, do that
        desired = "dark";
    }

    curScheme = desired;
    document.documentElement.setAttribute('data-theme', curScheme);

    // NOTE: The display indicator is updated in CSS
}

// click to move along states
function manualColorSchemeClick() {
    // figure out next color in sequence
    let curIndex = allowedSchemes.indexOf(curScheme);
    if (curIndex == -1) {
        console.error("Bad current color scheme:", curScheme);
        return;
    }
    // trigger logic that says user has picked that one
    let newScheme = allowedSchemes[(curIndex + 1) % allowedSchemes.length];

    let systemLight = systemWants("light");
    let systemDark = systemWants("dark");

    // if new pref is same as matchMedia(), then clear storage.
    if ((newScheme == "light" && systemLight) || (newScheme == "dark" && systemDark)) {
        window.localStorage.removeItem('color-scheme');
    } else {
        // if new pref differs from matchMedia(), set in storage.
        window.localStorage.setItem("color-scheme", newScheme);
    }

    // always set new scheme
    setColorScheme();
}

// Listener for when system color scheme changed. Call logic again.
window.matchMedia('(prefers-color-scheme: dark)').addEventListener('change', event => {
    setColorScheme();
});

// Set scheme on page load.
setColorScheme();

        </script>
        <!-- Hidden SVG for applying blur filters -->
        <svg class='hideSvgSoThatItSupportsFirefox dn'>
        <filter id='sharpBlur'>
            <feGaussianBlur stdDeviation='15'></feGaussianBlur>
            <feColorMatrix type='matrix' values='1 0 0 0 0, 0 1 0 0 0, 0 0 1 0 0, 0 0 0 9 0'></feColorMatrix>
            <feComposite in2='SourceGraphic' operator='in'></feComposite>
        </filter>
        </svg>

        

  
    <nav class="mh3 mh4-ns pv3 flex f6 f4-ns justify-between" aria-label="Main">
      <div class="tl">
        <a href="/" class="hover dim textcolor" id="header">Maxwell Forbes</a>
      </div>
      <div class="tr">
        
          
          
            <a class="link hover-link-color ml2 ml3-ns pv1" href="/studio">
              Studio
            </a>
          
        
          
          
            <a class="link hover-link-color ml2 ml3-ns pv1" href="/research">
              Research
            </a>
          
        
          
          
            <a class="link hover-link-color ml2 ml3-ns pv1" href="/about">
              About
            </a>
          
        

        
        <span class="ml2 ml3-ns" id="manualColorSchemeIndicator" onclick="manualColorSchemeClick()">
          <svg id="color-scheme-icon-light" class="color-scheme-icon" viewBox="0 0 50 50" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
              <title>sun</title>
              <g id="sun" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                  <g id="🌞" transform="translate(2.000000, 2.000000)" fill-rule="nonzero">
                      <path d="M17.1896054,47 L15.2897016,37.6903846 L6.31039461,40.6730769 L9.29595765,31.7024038 L0,29.8043269 L7.07940327,23.5 L0,17.1956731 L9.29595765,15.2975962 L6.31039461,6.32692308 L15.2897016,9.30961538 L17.1896054,0 L23.5,7.14038462 L29.8103946,0 L31.7102984,9.30961538 L40.6896054,6.32692308 L37.7040423,15.2975962 L47,17.1956731 L39.9205967,23.5 L47,29.8043269 L37.7040423,31.7024038 L40.6896054,40.6730769 L31.7102984,37.6903846 L29.8103946,47 L23.5,39.9048077 L17.1896054,47 Z M23.5,30.8889423 C21.3889958,30.8889423 19.5644851,30.2637821 18.0264678,29.0134615 L19.1573628,27.6802885 C20.3787295,28.6745192 21.8262753,29.1716346 23.5,29.1716346 C25.1737247,29.1716346 26.6212705,28.6745192 27.8426372,27.6802885 L28.9735322,29.0134615 C27.4355149,30.2637821 25.6110042,30.8889423 23.5,30.8889423 Z M17.0765159,22.0086538 C16.5940006,22.0086538 16.1831088,21.7939904 15.8438402,21.3646635 C15.5045717,20.9353365 15.3349374,20.411859 15.3349374,19.7942308 C15.3349374,19.1766026 15.5083414,18.656891 15.8551492,18.2350962 C16.201957,17.8133013 16.6090792,17.6024038 17.0765159,17.6024038 C17.5590311,17.6024038 17.969923,17.8133013 18.3091915,18.2350962 C18.6484601,18.656891 18.8180943,19.1766026 18.8180943,19.7942308 C18.8180943,20.411859 18.6484601,20.9353365 18.3091915,21.3646635 C17.969923,21.7939904 17.5590311,22.0086538 17.0765159,22.0086538 Z M23.5,38.8201923 C25.6260828,38.8201923 27.6126885,38.4247596 29.4598171,37.6338942 C31.3069458,36.8430288 32.9354347,35.7433494 34.3452839,34.3348558 C35.7551331,32.9263622 36.855871,31.2994391 37.6474976,29.4540865 C38.4391242,27.608734 38.8349374,25.6240385 38.8349374,23.5 C38.8349374,21.3759615 38.4391242,19.391266 37.6474976,17.5459135 C36.855871,15.7005609 35.7551331,14.0736378 34.3452839,12.6651442 C32.9354347,11.2566506 31.3069458,10.1569712 29.4598171,9.36610577 C27.6126885,8.57524038 25.6260828,8.17980769 23.5,8.17980769 C21.3739172,8.17980769 19.3873115,8.57524038 17.5401829,9.36610577 C15.6930542,10.1569712 14.0645653,11.2566506 12.6547161,12.6651442 C11.2448669,14.0736378 10.144129,15.7005609 9.35250241,17.5459135 C8.56087584,19.391266 8.16506256,21.3759615 8.16506256,23.5 C8.16506256,25.6240385 8.56087584,27.608734 9.35250241,29.4540865 C10.144129,31.2994391 11.2448669,32.9263622 12.6547161,34.3348558 C14.0645653,35.7433494 15.6930542,36.8430288 17.5401829,37.6338942 C19.3873115,38.4247596 21.3739172,38.8201923 23.5,38.8201923 Z M23.4321463,26.6408654 C22.9797883,26.6408654 22.42188,26.5278846 21.7584216,26.3019231 L22.3691049,24.7201923 C22.7762271,24.8557692 23.1305743,24.9235577 23.4321463,24.9235577 C23.6884825,24.9235577 23.8807347,24.8595353 24.0089028,24.7314904 C24.1370709,24.6034455 24.201155,24.4264423 24.201155,24.2004808 C24.201155,23.5979167 24.0541386,23.0443109 23.7601059,22.5396635 C23.4660731,22.035016 23.1682708,21.5077724 22.8666987,20.9579327 C22.5651267,20.4080929 22.4143407,19.7716346 22.4143407,19.0485577 C22.4143407,18.4610577 22.5613571,17.9036859 22.8553898,17.3764423 C23.1494225,16.8491987 23.5301572,16.4424679 23.9975938,16.15625 L24.8118383,17.6927885 C24.6308951,17.7831731 24.4801091,17.9677083 24.3594803,18.2463942 C24.2388515,18.5250801 24.1785371,18.7924679 24.1785371,19.0485577 C24.1785371,19.2895833 24.2313122,19.5456731 24.3368624,19.8168269 C24.4424126,20.0879808 24.6384344,20.4871795 24.9249278,21.0144231 C25.1511068,21.4211538 25.3735162,21.888141 25.5921559,22.4153846 C25.8107956,22.9426282 25.9201155,23.5376603 25.9201155,24.2004808 C25.9201155,24.9084936 25.6901668,25.4922276 25.2302695,25.9516827 C24.7703722,26.4111378 24.1709978,26.6408654 23.4321463,26.6408654 Z M29.9234841,22.0086538 C29.4409689,22.0086538 29.030077,21.7939904 28.6908085,21.3646635 C28.3515399,20.9353365 28.1819057,20.411859 28.1819057,19.7942308 C28.1819057,19.1766026 28.3553096,18.656891 28.7021174,18.2350962 C29.0489252,17.8133013 29.4560475,17.6024038 29.9234841,17.6024038 C30.4059994,17.6024038 30.8168912,17.8133013 31.1561598,18.2350962 C31.4954283,18.656891 31.6650626,19.1766026 31.6650626,19.7942308 C31.6650626,20.411859 31.4954283,20.9353365 31.1561598,21.3646635 C30.8168912,21.7939904 30.4059994,22.0086538 29.9234841,22.0086538 Z" id="Shape"></path>
                  </g>
              </g>
          </svg>
          <svg id="color-scheme-icon-dark" class="color-scheme-icon" viewBox="0 0 50 50" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
              <title>moon</title>
              <g id="moon" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                  <g id="🌝" transform="translate(2.000000, 1.000000)" fill-rule="nonzero">
                      <path d="M23.5,48 C20.2443902,48 17.195122,47.3769231 14.3521951,46.1307692 C11.5092683,44.8846154 9.0102439,43.1615385 6.85512195,40.9615385 C4.7,38.7615385 3.01869919,36.2115385 1.81121951,33.3115385 C0.603739837,30.4115385 0,27.3076923 0,24 C0,20.6923077 0.603739837,17.5884615 1.81121951,14.6884615 C3.01869919,11.7884615 4.7,9.23846154 6.85512195,7.03846154 C9.0102439,4.83846154 11.5092683,3.11538462 14.3521951,1.86923077 C17.195122,0.623076923 20.2443902,0 23.5,0 C26.7556098,0 29.804878,0.623076923 32.6478049,1.86923077 C35.4907317,3.11538462 37.9897561,4.83846154 40.144878,7.03846154 C42.3,9.23846154 43.9813008,11.7884615 45.1887805,14.6884615 C46.3962602,17.5884615 47,20.6923077 47,24 C47,27.3076923 46.3962602,30.4115385 45.1887805,33.3115385 C43.9813008,36.2115385 42.3,38.7615385 40.144878,40.9615385 C37.9897561,43.1615385 35.4907317,44.8846154 32.6478049,46.1307692 C29.804878,47.3769231 26.7556098,48 23.5,48 Z M23.1560976,36.7846154 L22.9268293,34.9615385 C23.5229268,34.9 24.0960976,34.7615385 24.6463415,34.5461538 C25.1965854,34.3307692 25.6856911,34.0846154 26.1136585,33.8076923 L27.122439,35.2846154 C26.0066667,36.0538462 24.6845528,36.5538462 23.1560976,36.7846154 Z M23.5,32.6769231 C21.039187,32.6769231 18.884065,31.9384615 17.0346341,30.4615385 L18.2497561,28.9846154 C19.7323577,30.2153846 21.482439,30.8307692 23.5,30.8307692 C25.517561,30.8307692 27.2676423,30.2153846 28.7502439,28.9846154 L29.9653659,30.4615385 C28.115935,31.9384615 25.960813,32.6769231 23.5,32.6769231 Z M13.6873171,22.8692308 C13.0912195,22.8692308 12.5639024,22.6730769 12.1053659,22.2807692 C11.6468293,21.8884615 11.417561,21.2923077 11.417561,20.4923077 C11.417561,19.5846154 11.7156098,18.8576923 12.3117073,18.3115385 C12.9078049,17.7653846 13.7026016,17.4923077 14.6960976,17.4923077 C15.7965854,17.4923077 16.8015447,17.8653846 17.7109756,18.6115385 C18.6204065,19.3576923 19.243252,20.4230769 19.5795122,21.8076923 L18.2726829,22.0846154 C17.9364228,21.5923077 17.5810569,21.1884615 17.2065854,20.8730769 C16.8321138,20.5576923 16.4461789,20.4 16.0487805,20.4 C15.9265041,20.4 15.8347967,20.4615385 15.7736585,20.5846154 C15.7125203,20.7076923 15.6819512,20.8307692 15.6819512,20.9538462 C15.6819512,21.3384615 15.5520325,21.7538462 15.2921951,22.2 C15.0323577,22.6461538 14.4973984,22.8692308 13.6873171,22.8692308 Z M23.5,46.1538462 C26.4957724,46.1538462 29.3043089,45.5807692 31.9256098,44.4346154 C34.5469106,43.2884615 36.8472358,41.7 38.8265854,39.6692308 C40.805935,37.6384615 42.3573171,35.2846154 43.4807317,32.6076923 C44.6041463,29.9307692 45.1658537,27.0615385 45.1658537,24 C45.1658537,20.9384615 44.6079675,18.0692308 43.4921951,15.3923077 C42.3764228,12.7153846 40.8250407,10.3615385 38.8380488,8.33076923 C36.8510569,6.3 34.5507317,4.71153846 31.9370732,3.56538462 C29.3234146,2.41923077 26.5110569,1.84615385 23.5,1.84615385 C20.5042276,1.84615385 17.6956911,2.41923077 15.0743902,3.56538462 C12.4530894,4.71153846 10.1489431,6.3 8.16195122,8.33076923 C6.17495935,10.3615385 4.62357724,12.7153846 3.50780488,15.3923077 C2.39203252,18.0692308 1.83414634,20.9384615 1.83414634,24 C1.83414634,27.0615385 2.39203252,29.9307692 3.50780488,32.6076923 C4.62357724,35.2846154 6.17495935,37.6384615 8.16195122,39.6692308 C10.1489431,41.7 12.4530894,43.2884615 15.0743902,44.4346154 C17.6956911,45.5807692 20.5042276,46.1538462 23.5,46.1538462 Z M23.3165854,28.2230769 C22.7357724,28.2230769 22.1014634,28.0923077 21.4136585,27.8307692 L22.0097561,26.1230769 C22.56,26.2923077 22.9956098,26.3769231 23.3165854,26.3769231 C23.6222764,26.3769231 23.8706504,26.2807692 24.0617073,26.0884615 C24.2527642,25.8961538 24.3482927,25.6692308 24.3482927,25.4076923 C24.3482927,24.7461538 24.1725203,24.1153846 23.8209756,23.5153846 C23.4694309,22.9153846 23.1178862,22.2769231 22.7663415,21.6 C22.4147967,20.9230769 22.2390244,20.1538462 22.2390244,19.2923077 C22.2390244,18.6 22.4071545,17.9461538 22.7434146,17.3307692 C23.0796748,16.7153846 23.5152846,16.2461538 24.0502439,15.9230769 L24.8985366,17.5846154 C24.6539837,17.7384615 24.4552846,17.9769231 24.302439,18.3 C24.1495935,18.6230769 24.0731707,18.9538462 24.0731707,19.2923077 C24.0731707,19.8615385 24.2489431,20.4576923 24.6004878,21.0807692 C24.9520325,21.7038462 25.3035772,22.3692308 25.655122,23.0769231 C26.0066667,23.7846154 26.182439,24.5615385 26.182439,25.4076923 C26.182439,26.2538462 25.9187805,26.9346154 25.3914634,27.45 C24.8641463,27.9653846 24.1725203,28.2230769 23.3165854,28.2230769 Z M29.7360976,22.8692308 C29.14,22.8692308 28.6126829,22.6730769 28.1541463,22.2807692 C27.6956098,21.8884615 27.4663415,21.2923077 27.4663415,20.4923077 C27.4663415,19.5846154 27.7643902,18.8576923 28.3604878,18.3115385 C28.9565854,17.7653846 29.7513821,17.4923077 30.744878,17.4923077 C31.8453659,17.4923077 32.8503252,17.8653846 33.7597561,18.6115385 C34.669187,19.3576923 35.2920325,20.4230769 35.6282927,21.8076923 L34.3214634,22.0846154 C33.9852033,21.5923077 33.6298374,21.1884615 33.2553659,20.8730769 C32.8808943,20.5576923 32.4949593,20.4 32.097561,20.4 C31.9752846,20.4 31.8835772,20.4615385 31.822439,20.5846154 C31.7613008,20.7076923 31.7307317,20.8307692 31.7307317,20.9538462 C31.7307317,21.3384615 31.600813,21.7538462 31.3409756,22.2 C31.0811382,22.6461538 30.5461789,22.8692308 29.7360976,22.8692308 Z" id="Shape"></path>
                  </g>
              </g>
          </svg>
          <svg id="color-scheme-icon-vaporwave" class="color-scheme-icon" viewBox="0 0 50 50" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
              <title>beach</title>
              <g id="beach" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                  <g id="🏝" transform="translate(4.345703, 1.068359)" fill-rule="nonzero">
                      <path d="M20.6772461,47.734375 C16.5463867,47.734375 12.9280599,47.3327637 9.82226562,46.529541 C6.71647135,45.7263184 4.30297852,44.6324056 2.58178711,43.2478027 C0.860595703,41.8631999 0,40.2911784 0,38.5317383 C0,37.1853841 0.627278646,35.9384766 1.88183594,34.7910156 C3.13639323,33.6435547 4.83081055,32.6796875 6.96508789,31.8994141 C9.09936523,31.1191406 11.4746094,30.6219076 14.0908203,30.4077148 L12.4155273,32.4731445 C10.4265951,32.6720378 8.63273112,33.0889486 7.03393555,33.723877 C5.43513997,34.3588053 4.16910807,35.1008301 3.23583984,35.9499512 C2.30257161,36.7990723 1.8359375,37.659668 1.8359375,38.5317383 C1.8359375,39.5415039 2.29874674,40.4938965 3.22436523,41.388916 C4.14998372,42.2839355 5.45808919,43.0680339 7.14868164,43.7412109 C8.83927409,44.414388 10.8320313,44.9422201 13.1269531,45.324707 C15.421875,45.707194 17.9386393,45.8984375 20.6772461,45.8984375 C23.4311523,45.8984375 25.9555664,45.7110189 28.2504883,45.3361816 C30.5454102,44.9613444 32.5305176,44.4373372 34.2058105,43.7641602 C35.8811035,43.0909831 37.1777344,42.3068848 38.0957031,41.4118652 C39.0136719,40.5168457 39.4726562,39.5568034 39.4726562,38.5317383 C39.4726562,37.6902669 38.9601237,36.8411458 37.9350586,35.984375 C36.9099935,35.1276042 35.5177409,34.3702799 33.7583008,33.7124023 C31.9988607,33.0545247 30.0175781,32.6031901 27.8144531,32.3583984 L27.8833008,30.6142578 C30.5148112,30.8896484 32.8365072,31.4251302 34.8483887,32.2207031 C36.8602702,33.016276 38.4399414,33.9610189 39.5874023,35.0549316 C40.7348633,36.1488444 41.3085938,37.3077799 41.3085938,38.5317383 C41.3085938,40.3370768 40.4365234,41.9320475 38.6923828,43.3166504 C36.9482422,44.7012533 34.5270996,45.7836914 31.4289551,46.5639648 C28.3308105,47.3442383 24.7469076,47.734375 20.6772461,47.734375 Z M10.7172852,42.9838867 C9.89111328,42.6778971 8.92724609,41.9358724 7.82568359,40.7578125 C7.3819987,40.2682292 7.03776042,39.9316406 6.79296875,39.7480469 C6.54817708,39.5644531 6.24983724,39.3732096 5.89794922,39.1743164 C5.57666016,38.9907227 5.35099284,38.8453776 5.22094727,38.7382812 C5.09090169,38.6311849 4.97233073,38.5011393 4.86523438,38.3481445 L5.94384766,37.6137695 C6.2804362,37.9044596 6.65527344,38.1377767 7.06835938,38.3137207 C7.48144531,38.4896647 8.0398763,38.9754232 8.74365234,39.7709961 C9.66162109,40.7960612 10.457194,41.4386393 11.1303711,41.6987305 L10.7172852,42.9838867 Z M17.8085938,26.3227539 C16.7070312,26.0167643 15.8311361,25.4200846 15.1809082,24.5327148 C14.5306803,23.6453451 14.2055664,22.5284831 14.2055664,21.1821289 C14.2055664,21.0138346 14.2055664,20.8531901 14.2055664,20.7001953 C14.2055664,20.5472005 14.2132161,20.3942057 14.2285156,20.2412109 L9.84521484,24.6245117 C8.98844401,23.293457 8.56005859,21.8017578 8.56005859,20.1494141 C8.56005859,18.7724609 8.85457357,17.5217285 9.44360352,16.3972168 C10.0326335,15.2727051 10.8626302,14.3203125 11.9335938,13.5400391 L7.06835938,13.4711914 C7.00716146,13.2263997 6.9765625,12.9586589 6.9765625,12.6679688 C6.9765625,11.4440104 7.3055013,10.3730469 7.96337891,9.45507812 C8.62125651,8.53710938 9.48185221,7.82568359 10.545166,7.32080078 C11.6084798,6.81591797 12.7291667,6.56347656 13.9072266,6.56347656 C14.7945964,6.56347656 15.6513672,6.70117188 16.4775391,6.9765625 C16.4622396,6.88476562 16.4545898,6.78914388 16.4545898,6.68969727 C16.4545898,6.59025065 16.4545898,6.49462891 16.4545898,6.40283203 C16.4545898,4.47509766 17.0550944,2.92602539 18.2561035,1.75561523 C19.4571126,0.585205078 21.0597331,0 23.0639648,0 C23.4464518,0 23.7753906,0.0229492188 24.0507812,0.0688476562 L23.5458984,4.93408203 C24.3108724,4.30680339 25.1140951,3.82869466 25.9555664,3.49975586 C26.7970378,3.17081706 27.6461589,3.00634766 28.5029297,3.00634766 C29.6809896,3.00634766 30.7481283,3.3046875 31.7043457,3.90136719 C32.6605632,4.49804688 33.3528646,5.29361979 33.78125,6.28808594 L28.8012695,9.84521484 C30.8513997,9.92171224 32.4501953,10.5375163 33.5976562,11.692627 C34.7451172,12.8477376 35.3188477,14.3585612 35.3188477,16.2250977 C35.3188477,17.4643555 35.1276042,18.4129232 34.7451172,19.0708008 L23.1098633,15.7202148 L17.8085938,26.3227539 Z M25.2441406,43.8789062 L25.175293,42.4790039 C25.4047852,42.4025065 25.6610514,42.3527832 25.9440918,42.329834 C26.2271322,42.3068848 26.4910482,42.2954102 26.7358398,42.2954102 C28.1892904,42.2954102 29.2908529,42.1959635 30.0405273,41.9970703 C30.7902018,41.7981771 31.3639323,41.5304362 31.7617188,41.1938477 C32.1595052,40.8572591 32.5458171,40.4824219 32.9206543,40.0693359 C33.2954915,39.65625 33.8347982,39.2355143 34.5385742,38.8071289 L35.2729492,40.0234375 C34.7068685,40.3294271 34.2249349,40.6889648 33.8271484,41.1020508 C33.429362,41.5151367 32.9780273,41.916748 32.4731445,42.3068848 C31.9682617,42.6970215 31.2721354,43.0221354 30.3847656,43.2822266 C29.4973958,43.5423177 28.2810872,43.6723633 26.7358398,43.6723633 C26.5369466,43.6723633 26.2921549,43.6876628 26.0014648,43.7182617 C25.7107747,43.7488607 25.4583333,43.8024089 25.2441406,43.8789062 Z M26.2998047,29.6044922 C25.733724,29.6044922 25.1944173,29.5624186 24.6818848,29.4782715 C24.1693522,29.3941243 23.675944,29.2679036 23.2016602,29.0996094 L23.706543,27.8144531 C24.5174154,28.0898438 25.3665365,28.2275391 26.2539062,28.2275391 C26.8658854,28.2275391 27.4855143,28.1739909 28.112793,28.0668945 L28.3193359,29.4438477 C27.9827474,29.4897461 27.642334,29.5279948 27.2980957,29.5585938 C26.9538574,29.5891927 26.6210938,29.6044922 26.2998047,29.6044922 Z M24.0048828,25.8637695 L24.0048828,24.4868164 C24.8310547,24.4868164 25.5386556,24.4485677 26.1276855,24.3720703 C26.7167155,24.2955729 27.141276,24.1961263 27.4013672,24.0737305 L28.112793,25.2900391 C27.6079102,25.5348307 26.9423828,25.6916504 26.1162109,25.760498 C25.2900391,25.8293457 24.586263,25.8637695 24.0048828,25.8637695 Z M23.8442383,22.2607422 L23.8442383,20.8837891 C24.8846029,20.8837891 25.733724,20.6542969 26.3916016,20.1953125 L27.3095703,21.2739258 C26.3610026,21.9318034 25.2058919,22.2607422 23.8442383,22.2607422 Z M25.6342773,33.0927734 C24.2726237,33.0927734 23.2819824,32.9359538 22.6623535,32.6223145 C22.0427246,32.3086751 21.7329102,31.6928711 21.7329102,30.7749023 C21.7329102,30.3771159 21.7864583,29.9869792 21.8935547,29.6044922 C22.000651,29.2220052 22.1230469,28.847168 22.2607422,28.4799805 C22.4749349,27.9291992 22.6661784,27.3172201 22.8344727,26.644043 C23.0027669,25.9708659 23.0869141,25.144694 23.0869141,24.1655273 C23.0869141,23.0333659 22.9377441,21.9509277 22.6394043,20.9182129 C22.3410645,19.885498 21.8400065,18.7648112 21.1362305,17.5561523 L22.5361328,16.7529297 C23.2858073,18.0533854 23.8327637,19.2964681 24.177002,20.4821777 C24.5212402,21.6678874 24.6933594,22.8956706 24.6933594,24.1655273 C24.6933594,25.2823893 24.5939128,26.230957 24.3950195,27.0112305 C24.1961263,27.7915039 23.9895833,28.4723307 23.7753906,29.0537109 C23.6223958,29.4667969 23.5114746,29.8033854 23.442627,30.0634766 C23.3737793,30.3235677 23.3393555,30.5607096 23.3393555,30.7749023 C23.3393555,31.050293 23.442627,31.2377116 23.6491699,31.3371582 C23.8557129,31.4366048 24.5174154,31.4863281 25.6342773,31.4863281 C26.6287435,31.4863281 27.229248,31.4519043 27.435791,31.3830566 C27.642334,31.314209 27.7456055,31.2415365 27.7456055,31.1650391 C27.7456055,24.8310547 26.5598958,19.7516276 24.1884766,15.9267578 L25.5654297,15.0776367 C28.0898438,19.1778971 29.3520508,24.5403646 29.3520508,31.1650391 C29.3520508,31.9453125 29.0384115,32.4616699 28.4111328,32.7141113 C27.7838542,32.9665527 26.8582357,33.0927734 25.6342773,33.0927734 Z M22.7885742,19.1396484 L22.7885742,17.7626953 C23.7983398,17.7626953 24.6321615,17.5255534 25.2900391,17.0512695 L26.2080078,18.1298828 C25.7796224,18.4205729 25.2517904,18.6615397 24.6245117,18.8527832 C23.9972331,19.0440267 23.3852539,19.1396484 22.7885742,19.1396484 Z M22.0541992,15.3759766 L19.1166992,14.3891602 C18.7954102,14.2667643 18.6347656,14.0602214 18.6347656,13.7695312 C18.6347656,13.4176432 18.8183594,13.2416992 19.1855469,13.2416992 C19.3538411,13.2416992 19.5221354,13.2722982 19.6904297,13.3334961 L21.5263672,13.9990234 L20.4248047,12.0024414 C20.3177083,11.8341471 20.2641602,11.6658529 20.2641602,11.4975586 C20.2641602,11.1456706 20.4401042,10.9697266 20.7919922,10.9697266 C21.0367839,10.9697266 21.2433268,11.1150716 21.4116211,11.4057617 L22.6508789,13.5400391 L22.9492188,12.0024414 C23.0410156,11.5128581 23.2552083,11.2680664 23.5917969,11.2680664 C23.7600911,11.2680664 23.8939616,11.3522135 23.9934082,11.5205078 C24.0928548,11.6888021 24.1119792,11.9029948 24.0507812,12.1630859 L23.5458984,14.7104492 L22.0541992,15.3759766 Z M19.4838867,36.0532227 C18.917806,36.0532227 18.4435221,35.8619792 18.0610352,35.4794922 C17.6785482,35.0970052 17.4873047,34.6303711 17.4873047,34.0795898 C17.4873047,33.5288086 17.6785482,33.0621745 18.0610352,32.6796875 C18.4435221,32.2972005 18.917806,32.105957 19.4838867,32.105957 C20.034668,32.105957 20.5013021,32.2972005 20.8837891,32.6796875 C21.266276,33.0621745 21.4575195,33.5288086 21.4575195,34.0795898 C21.4575195,34.6303711 21.266276,35.0970052 20.8837891,35.4794922 C20.5013021,35.8619792 20.034668,36.0532227 19.4838867,36.0532227 Z M20.4018555,40.9414062 C19.7745768,40.9414062 19.2084961,40.8190104 18.7036133,40.5742188 C18.1987305,40.3294271 17.6900228,40.0846354 17.1774902,39.8398438 C16.6649577,39.5950521 16.0797526,39.4726562 15.421875,39.4726562 C14.9169922,39.4726562 14.335612,39.5032552 13.6777344,39.5644531 C12.7444661,39.65625 12.0062663,39.6141764 11.4631348,39.4382324 C10.9200033,39.2622884 10.4036458,38.891276 9.9140625,38.3251953 C9.73046875,38.1110026 9.55452474,37.923584 9.38623047,37.7629395 C9.2179362,37.6022949 8.9387207,37.3575033 8.54858398,37.0285645 C8.15844727,36.6996257 7.52734375,36.190918 6.65527344,35.5024414 C7.66503906,34.1407878 8.92342122,32.9550781 10.4304199,31.9453125 C11.9374186,30.9355469 13.570638,30.1514486 15.3300781,29.5930176 C17.0895182,29.0345866 18.8489583,28.7553711 20.6083984,28.7553711 C21.1132812,28.7553711 21.6258138,28.7706706 22.1459961,28.8012695 C22.6661784,28.8318685 23.1940104,28.8854167 23.7294922,28.9619141 L22.765625,30.6601562 C22.1077474,30.6142578 21.3886719,30.5913086 20.6083984,30.5913086 C18.9254557,30.5913086 17.4031576,30.7825521 16.0415039,31.1650391 C14.6798503,31.547526 13.4482422,32.0906576 12.3466797,32.7944336 C11.2451172,33.4982096 10.2200521,34.3243815 9.27148438,35.2729492 C9.86816406,35.7472331 10.2927246,36.0991211 10.545166,36.3286133 C10.7976074,36.5581055 11.046224,36.8181966 11.2910156,37.1088867 C11.5817057,37.4301758 11.8570964,37.6328939 12.1171875,37.717041 C12.3772786,37.8011882 12.836263,37.805013 13.4941406,37.7285156 C13.8919271,37.6826172 14.2361654,37.6558431 14.5268555,37.6481934 C14.8175456,37.6405436 15.1158854,37.6367188 15.421875,37.6367188 C16.125651,37.6367188 16.7758789,37.7591146 17.3725586,38.0039062 C17.9692383,38.2486979 18.5238444,38.4934896 19.036377,38.7382812 C19.5489095,38.9830729 20.004069,39.1054688 20.4018555,39.1054688 C20.8455404,39.1054688 21.2854004,38.9754232 21.7214355,38.715332 C22.1574707,38.4552409 22.6508789,38.1989746 23.2016602,37.9465332 C23.7524414,37.6940918 24.410319,37.5678711 25.175293,37.5678711 C25.4047852,37.5678711 25.7757975,37.5984701 26.2883301,37.659668 C26.8008626,37.7208659 27.3210449,37.7667643 27.848877,37.7973633 C28.376709,37.8279622 28.7630208,37.8126628 29.0078125,37.7514648 C29.6044922,37.5831706 30.139974,37.2389323 30.6142578,36.71875 C31.0885417,36.1985677 31.5704753,35.7625326 32.0600586,35.4106445 C31.6316732,34.9210612 31.1114909,34.3855794 30.4995117,33.8041992 C29.8875326,33.222819 29.1761068,32.6873372 28.3652344,32.1977539 L31.4404297,32.7485352 C32.1442057,33.2840169 32.7600098,33.8271484 33.2878418,34.3779297 C33.8156738,34.9287109 34.2249349,35.5330404 34.515625,36.190918 C33.7353516,36.4357096 33.1233724,36.7684733 32.6796875,37.189209 C32.2360026,37.6099447 31.7999674,38.0345052 31.371582,38.4628906 C30.9431966,38.891276 30.3541667,39.2355143 29.6044922,39.4956055 C29.2373047,39.6180013 28.7553711,39.6677246 28.1586914,39.6447754 C27.5620117,39.6218262 26.9844564,39.5759277 26.4260254,39.5070801 C25.8675944,39.4382324 25.4506836,39.4038086 25.175293,39.4038086 C24.5174154,39.4038086 23.9551595,39.5300293 23.4885254,39.7824707 C23.0218913,40.0349121 22.5552572,40.2911784 22.088623,40.5512695 C21.6219889,40.8113607 21.0597331,40.9414062 20.4018555,40.9414062 Z M17.0053711,23.8442383 L22.1459961,13.5400391 L33.4599609,16.7988281 C33.4752604,16.6764323 33.4829102,16.4851888 33.4829102,16.2250977 C33.4829102,14.7716471 33.0736491,13.6280111 32.255127,12.7941895 C31.4366048,11.9603678 30.2317708,11.543457 28.640625,11.543457 C28.3499349,11.543457 28.0592448,11.5587565 27.7685547,11.5893555 C27.4778646,11.6199544 27.1871745,11.6811523 26.8964844,11.7729492 L25.7260742,9.77636719 L31.2568359,5.82910156 C30.5071615,5.17122396 29.5891927,4.84228516 28.5029297,4.84228516 C28.0286458,4.84228516 27.4013672,4.96085612 26.6210938,5.19799805 C25.8408203,5.43513997 25.0146484,6.00504557 24.1425781,6.90771484 L21.5493164,6.26513672 L22.0541992,1.60644531 L23.0639648,1.74414062 C21.5799154,1.74414062 20.4133301,2.1648763 19.564209,3.00634766 C18.7150879,3.84781901 18.2905273,4.97998047 18.2905273,6.40283203 C18.2905273,6.67822266 18.2981771,6.90771484 18.3134766,7.09130859 C18.328776,7.27490234 18.3670247,7.51204427 18.4282227,7.80273438 L16.7988281,9.11083984 C16.2633464,8.8507487 15.7546387,8.66715495 15.2727051,8.56005859 C14.7907715,8.45296224 14.335612,8.39941406 13.9072266,8.39941406 C12.484375,8.39941406 11.279541,8.78190104 10.2927246,9.546875 C9.3059082,10.311849 8.8125,11.3522135 8.8125,12.6679688 L8.51416016,11.7041016 L15.1694336,11.7041016 L15.1694336,13.953125 C13.3334961,14.5957031 12.0789388,15.5021973 11.4057617,16.6726074 C10.7325846,17.8430176 10.3959961,19.0019531 10.3959961,20.1494141 C10.3959961,20.531901 10.4342448,20.9373372 10.5107422,21.3657227 L15.3759766,16.5004883 L16.8676758,17.7626953 C16.5769857,18.2828776 16.3666178,18.8145345 16.2365723,19.357666 C16.1065267,19.9007975 16.0415039,20.5089518 16.0415039,21.1821289 C16.0415039,22.3295898 16.362793,23.2169596 17.0053711,23.8442383 Z" id="Shape"></path>
                  </g>
              </g>
          </svg>
        </span>
      </div>
    </nav>


  
  <div class="mw7 mb3 center">
    <main class="tl relative ph3 ph4-ns pt4 pt5-l pb2 paddingOverride">
      
        <div class="mb4">
          
          
            <div class="f6 f5-ns lightest-text-color mt0 mb2">
              
                Nov 21, 2017
              
            </div>
          

          
          

          
          <h1 class="f1 f-5-l fw9 lh-solid mt0 mb5">
              Ordinary least squares, ℓ² (ridge), and ℓ¹ (lasso) linear regressions
          </h1>
          

        </div>
      

      
      

      <div class="markdown-body">
        <h2 id="preface" tabindex="-1">Preface</h2>
<a class="dn" href="#preface"><span class="dn">Permalink to “Preface”</span> <span aria-hidden="true">#</span></a><p><em>I wrote this in 2017, and am posting it now in 2021. I was surprised how difficult it was to find complete information about linear regressions in one place: the derivations of the gradients, how they get their properties (e.g., lasso’s sparsity requiring coordinate descent), and some simple code to implement them. I tried to be careful about vector shapes and algebra, but there are probably still minor errors, which are of course my own.</em></p>
<p><em>One big goof I had was running this on MNIST, which ought to be treated as a classification problem per class (e.g., with logistic regression), rather than trying to regress each digit to a number (e.g., the digit “1” to the number <code>1</code>, and the digit “5” to the number <code>5</code>). I should have ran this code on a true regression dataset instead, where you do want real numbers (rather than class decisions) as output.</em></p>
<p><em>However, the silver lining is that after this goof, I was in a computer architecture class where we needed to run MNIST classification on FPGAs, and the starter code had made exactly this same mistake—they were doing linear instead of logistic regression! Making that simple switch resulted in such an accuracy boost that the classifier became one of the pareto optimal ones.</em></p>
<p><em>The repository for this project, which contains the full writeup below, as well as simple pytorch code to implement it, is here:</em></p>
<style>
    .black-and-white:not(:hover) {
        filter: grayscale(100%);
    }
</style>
<link href='/assets/css/tippy-6.3.1.light.css' rel="stylesheet" type="text/css"/>
<script defer src='/assets/lib/popper-2.9.3.min.js'></script>
<script defer src='/assets/lib/tippy-6.3.1.umd.min.js'></script>
<script>
    document.addEventListener('DOMContentLoaded', function () {
        const langs = [
            'Python',
            'TypeScript',
            'Bash',
            'Java',
            'HTML',
            'JavaScript',
            'Ruby',
            'PHP'
        ];
        for (let lang of langs) {
            let lower = lang.toLowerCase();
            tippy(`.${lower}`, {
                content: `Written in ${lang}`,
                theme: 'light'
            });
        }
    });
</script>
<div class="pl3 bl bw1 mb4">
    <a href="https://github.com/mbforbes/rndjam1" class="f5 f4-ns b code">rndjam1</a><span class="dib fr">
            <img
                class="h1 novmargin mt1 black-and-white python"
                src="/assets/img/langs/python.svg"/>
        </span><p class="mv1 f5 f4-ns">Regression derivations (+ basic code running on MNIST): ordinary least squares, ridge (ℓ²), and lasso (ℓ¹).</p></div>
<p><em>Enjoy!</em></p>
<p><em>– Max from 2021</em></p>
<h2 id="goal" tabindex="-1">Goal</h2>
<a class="dn" href="#goal"><span class="dn">Permalink to “Goal”</span> <span aria-hidden="true">#</span></a><p><strong>Build</strong> linear regression for MNIST from scratch using pytorch.</p>
<h2 id="data-splits" tabindex="-1">Data splits</h2>
<a class="dn" href="#data-splits"><span class="dn">Permalink to “Data splits”</span> <span aria-hidden="true">#</span></a><p>MNIST (<a href="https://pjreddie.com/projects/mnist-in-csv/">csv version</a>) has a 60k/10k train/test split.</p>
<p>I pulled the last 10k off of train for a val set.</p>
<p>My final splits are then 50k/10k/10k train/val/test.</p>
<h2 id="viewing-an-image" tabindex="-1">Viewing an image</h2>
<a class="dn" href="#viewing-an-image"><span class="dn">Permalink to “Viewing an image”</span> <span aria-hidden="true">#</span></a><p>Here’s an MNIST image:</p>
<p><img src="/assets/posts/regression-math/images/example_normal.jpg" alt="the first mnist datum"></p>
<p>Here it is expanded 10x:</p>
<p><img src="/assets/posts/regression-math/images/example_bloated.jpg" alt="the first mnist datum, expanded"></p>
<h2 id="data-loading:-csv-vs-binary-(&quot;tensor&quot;)" tabindex="-1">Data loading: CSV vs binary (“tensor”)</h2>
<a class="dn" href="#data-loading:-csv-vs-binary-(&quot;tensor&quot;)"><span class="dn">Permalink to “Data loading: CSV vs binary (“tensor”)”</span> <span aria-hidden="true">#</span></a><p>y-axis is seconds taken to load the file; lower is better. Result: binary is
way faster.</p>
<p><img src="/assets/posts/regression-math/images/data_loading.png" alt="data loading speeds, csv vs binary"></p>
<h2 id="naive-regression-to-scalar" tabindex="-1">Naive regression to scalar</h2>
<a class="dn" href="#naive-regression-to-scalar"><span class="dn">Permalink to “Naive regression to scalar”</span> <span aria-hidden="true">#</span></a><p>In this we regress each image to a scalar that is the number represented in
that image. For example, we regress the image <img alt="the first MNIST datum" src="/assets/posts/regression-math/images/example_normal.jpg" class="inline ph2"> to the number <code>5</code>.</p>
<blockquote>
<p>Disclaimer: this is a suboptimal approach. If you’re going to treat was is really a
classification problem (like MNIST) as regression, you should regress to each
class independently (i.e., do 10 regression problems at once instead of a
single regression). Explaining why would take math that I would have to talk
to people smarter than me to produce. I think the intuition is that you’re
making the learning problem harder by forcing these distinct classes to exist
as points in a 1D real space, when they really have no relation to each
other. This is better treated as a logistic regression problem.</p>
<p>However: (a) if you’re confused like I was, you might try it, (b) if you’re bad at
math like me, it’s simpler to start out with a “normal” regression than 10 of
them, (c) I’m kind of treating this like a notebook, so might as well
document the simple → complex progression of what I tried.</p>
<p>So here we go.</p>
</blockquote>
<h3 id="notation" tabindex="-1">Notation</h3>
<a class="dn" href="#notation"><span class="dn">Permalink to “Notation”</span> <span aria-hidden="true">#</span></a><p>Definitions:</p>
<p><img src="/assets/posts/regression-math/svg/definitions.svg" alt="definitions"></p>
<p>Math reminders and my notation choices:</p>
<p><img src="/assets/posts/regression-math/svg/math-reminders.svg" alt="math reminders"></p>
<blockquote>
<p>NB: While the derivative of a function <strong>f</strong> : ℝ<sup>n</sup> → ℝ is
<a href="https://en.wikipedia.org/wiki/Jacobian_matrix_and_determinant">technically a row
vector</a>,
people™ have decided that gradients of functions are column vectors,
which is why I have transposes sprinkled below. (Thanks to Chris Xie for
explaining this.)</p>
</blockquote>
<h3 id="ordinary-least-squares-(ols)" tabindex="-1">Ordinary least squares (OLS)</h3>
<a class="dn" href="#ordinary-least-squares-(ols)"><span class="dn">Permalink to “Ordinary least squares (OLS)”</span> <span aria-hidden="true">#</span></a><p><strong>Loss</strong> (average per datum):</p>
<p><img src="/assets/posts/regression-math/svg/least-squares-loss.svg" alt="least squares loss"></p>
<p>Using the average loss per datum is nice because it is invariant of the dataset
(or (mini)batch) size, which will come into play when we do gradient
descent. Expanding the loss function out for my noob math:</p>
<p><img src="/assets/posts/regression-math/svg/least-squares-loss-expanded.svg" alt="least squares loss expanded"></p>
<p>Taking the <strong>derivative</strong> of the loss function with respect to the <strong>weight
vector</strong>:</p>
<p><img src="/assets/posts/regression-math/svg/least-squares-loss-expanded-derivative.svg" alt="least squares loss expanded derivative"></p>
<p>We can set the gradient equal to 0 (the zero vector) and solve for the
<strong>analytic solution</strong> (omitting second derivative check):</p>
<p><img src="/assets/posts/regression-math/svg/least-squares-analytic-expanded.svg" alt="least squares analytic expanded"></p>
<p>Doing a little bit of algebra to clean up the gradient, we’ll get our
<strong>gradient for gradient descent</strong>:</p>
<p><img src="/assets/posts/regression-math/svg/least-squares-gradient.svg" alt="least squares gradient"></p>
<p>We can plot the loss as we take more gradient descent steps:</p>
<p><img src="/assets/posts/regression-math/images/ols_gd_linear.png" alt="ols gradient descent linear plot"></p>
<p>… but it’s hard to see what’s happening. That’s because the loss starts so
high and the y-axis is on a linear scale. A log scale is marginally more
informative:</p>
<p><img src="/assets/posts/regression-math/images/ols_gd_log.png" alt="ols gradient descent log plot"></p>
<p>To instead do <strong>coordinate descent</strong>, we optimize a single coordinate at a
time, keeping all others fixed. We take the <strong>derivative</strong> of the loss function
with respect to a <strong>single weight</strong>:</p>
<p><img src="/assets/posts/regression-math/svg/least-squares-derivative-single-weight.svg" alt="least squares derivative single weight"></p>
<p>Setting the derivative equal to zero, we can solve for the optimal value for
that single weight:</p>
<p><img src="/assets/posts/regression-math/svg/least-squares-derivative-single-weight-zero.svg" alt="least squares derivative single weight zero"></p>
<p>However, this is an expensive update to a single weight. We can speed this up.
If we define the residual,</p>
<p><img src="/assets/posts/regression-math/svg/residual.svg" alt="residual"></p>
<p>then we can rewrite the inner term above as,</p>
<p><img src="/assets/posts/regression-math/svg/least-squares-residual-rewrite.svg" alt="least squares residual rewrite"></p>
<p>and, using <code>(t)</code> and <code>(t+1)</code> to clarify old and new values for the weight,
rewrite the single weight optimum as:</p>
<p><img src="/assets/posts/regression-math/svg/least-squares-coord-descent.svg" alt="least squares coord descent"></p>
<p>After updating that weight, <strong>r</strong> is immediately stale, so we must update it as
well:</p>
<p><img src="/assets/posts/regression-math/svg/least-squares-coord-descent-r-update.svg" alt="least squares coord descent r update"></p>
<p>We can compute an initial <strong>r</strong> and we can precompute all of the column norms
(the denominator) because they do not change. That means that each weight
update involves just the <em>n</em>-dimensional vector dot product (the numerator) and
updating <strong>r</strong> (<em>n</em>-dimensional operations). Because of this, one full round of
coordinate descent (updating all weight coordinates once) is said to have the
same update time complexity as one step of gradient descent (<code>O(nd)</code>).</p>
<p>However, I found that in practice, one step of (vanilla) gradient descent is
much faster. I think this is because my implementation of coordinate descent
requires moving values to and from the GPU (for bookkeeping old values),
whereas gradient descent can run entirely on the GPU. I’m not sure if I can
remedy this. With that said, coordinate descent converges with 10x fewer
iterations.</p>
<p><img src="/assets/posts/regression-math/images/ols_cd.png" alt="ols coordinate descent plot"></p>
<p>But how well do we do in regressing to a scalar with OLS?</p>
<p><img src="/assets/posts/regression-math/images/ols_acc.png" alt="ols accuracy"></p>
<p>Not very well.</p>
<h3 id="ridge-regression-(rr)" tabindex="-1">Ridge regression (RR)</h3>
<a class="dn" href="#ridge-regression-(rr)"><span class="dn">Permalink to “Ridge regression (RR)”</span> <span aria-hidden="true">#</span></a><p><strong>Loss:</strong></p>
<p><img src="/assets/posts/regression-math/svg/ridge-loss.svg" alt="ridge loss"></p>
<blockquote>
<p>NB: For all regularization methods (e.g., ridge and lasso), we shouldn’t be
regularizing the weight corresponding to the bias term (I added as an extra
feature column of <code>1</code>s). You can remedy this by either (a) centering the <code>y</code>s
and omitting the bias term, or (b) removing the regularization of the bias
weight in the loss and gradient. I tried doing (b) but I think I failed (GD
wasn’t getting nearly close enough to analytic loss), so I’ve left the
normalization in there for now (!).</p>
</blockquote>
<p><strong>Derivative:</strong></p>
<p>(Being a bit more liberal with my hand waving of vector and matrix derivatives
than above)</p>
<p><img src="/assets/posts/regression-math/svg/ridge-derivative.svg" alt="ridge derivative"></p>
<p><strong>Analytic:</strong></p>
<blockquote>
<p>NB: I think some solutions combine <em>n</em> into <em>λ</em> because it looks cleaner. In
order to get the analytic solution and gradient (descent) to reach the same
solution, I needed to be consistent with how I applied <em>n</em>, so I’ve left it
in for completeness.</p>
</blockquote>
<p><img src="/assets/posts/regression-math/svg/ridge-analytic.svg" alt="ridge analytic"></p>
<p><strong>Gradient:</strong></p>
<p>(Just massaging the derivative we found a bit more.)</p>
<p><img src="/assets/posts/regression-math/svg/ridge-gradient.svg" alt="ridge gradient"></p>
<p><strong>Coordinate descent:</strong></p>
<p>The derivative of the regularization term with respect to a single weight is:</p>
<p><img src="/assets/posts/regression-math/svg/ridge-cd-0.svg" alt="ridge cd 0"></p>
<p>with that in mind, the derivative of the loss function with respect to a single
weight is:</p>
<p><img src="/assets/posts/regression-math/svg/ridge-cd-1.svg" alt="ridge cd 1"></p>
<p>In setting this equal to 0 and solving, I’m going to do some serious hand
waving about “previous” versus “next” values of the weight. (I discovered what
seems (empirically) to be the correct form by modifying late equations of the
Lasso coordinate descent update, but I’m not sure the correct way to do the
derivation here.) We’ll also make use of the residual
<img src="/assets/posts/regression-math/svg/residual.svg" alt="residual">.</p>
<p><img src="/assets/posts/regression-math/svg/ridge-cd-2.svg" alt="ridge cd 2"></p>
<p>As above, we update the residual after each weight update:</p>
<p><img src="/assets/posts/regression-math/svg/residual-update.svg" alt="residual update"></p>
<h3 id="lasso" tabindex="-1">Lasso</h3>
<a class="dn" href="#lasso"><span class="dn">Permalink to “Lasso”</span> <span aria-hidden="true">#</span></a><p><strong>Loss:</strong></p>
<p><img src="/assets/posts/regression-math/svg/lasso-loss.svg" alt="lasso loss"></p>
<p><strong>Derivative:</strong></p>
<p><img src="/assets/posts/regression-math/svg/lasso-derivative-part1.svg" alt="lasso derivative part 1"></p>
<p>Focusing on the final term, we’ll use the subgradient, and pick <code>0</code> (valid in
<code>[-1, 1]</code>) for the nondifferentiable point. This means we can use <code>sgn(x)</code> as
the “derivative” of <code>|x|</code>.</p>
<p><img src="/assets/posts/regression-math/svg/lasso-derivative-part2.svg" alt="lasso derivative part 2"></p>
<p>Substitute in to get the final term for the (sub)gradient:</p>
<p><img src="/assets/posts/regression-math/svg/lasso-derivative-part3.svg" alt="lasso derivative part 3"></p>
<blockquote>
<p>NB: There’s no soft thresholding (sparsity-encouraging) property of LASSO
when you use gradient descent. You need something like coordinate descent to
get that. Speaking of which…</p>
</blockquote>
<p><strong>Coordinate descent:</strong></p>
<p><img src="/assets/posts/regression-math/svg/lasso-cd-1.svg" alt="lasso cd 1"></p>
<p>setting this = 0, and again using the residual <img src="/assets/posts/regression-math/svg/residual.svg" alt="residual">,
we have:</p>
<p><img src="/assets/posts/regression-math/svg/lasso-cd-2.svg" alt="lasso cd 2"></p>
<blockquote>
<p>NB: I think that here (and below) we might really be saying that 0 is in the
set of subgradients, rather than that it equals zero.</p>
</blockquote>
<p>There’s a lot going on. Let’s define two variables to clean up our equation:</p>
<p><img src="/assets/posts/regression-math/svg/lasso-cd-3.svg" alt="lasso cd 3"></p>
<p>From this, we can more clearly see the solution to this 1D problem:</p>
<p><img src="/assets/posts/regression-math/svg/lasso-cd-4.svg" alt="lasso cd 4"></p>
<p>This solution is exactly the soft threshold operator:</p>
<p><img src="/assets/posts/regression-math/svg/lasso-cd-5.svg" alt="lasso cd 5"></p>
<p>Rewriting this into its full form:</p>
<p><img src="/assets/posts/regression-math/svg/lasso-cd-6.svg" alt="lasso cd 6"></p>
<p>As with coordinate descent above, we need to update the residual <strong>r</strong> after
each weight update (skipping the derivation; same as above for OLS):</p>
<p><img src="/assets/posts/regression-math/svg/residual-update.svg" alt="residual update"></p>
<h2 id="links" tabindex="-1">Links</h2>
<a class="dn" href="#links"><span class="dn">Permalink to “Links”</span> <span aria-hidden="true">#</span></a><ul>
<li><a href="https://en.wikipedia.org/wiki/Regularized_least_squares#Partial_list_of_RLS_methods">Table of regularized least squares functions (Wikipedia)</a></li>
<li><a href="https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf">The Matrix Cookbook (Petersen &amp; Pedersen)</a></li>
<li><a href="https://web.stanford.edu/~mrosenfe/soc_meth_proj3/matrix_OLS_NYU_notes.pdf">OLS with matrices notes (possibly Rosenfeld?)</a></li>
<li><a href="https://www.cs.cmu.edu/~ggordon/10725-F12/slides/25-coord-desc.pdf">Coordinate Descent (Gordon &amp; Tibshirani)</a></li>
<li><a href="http://jocelynchi.com/a-coordinate-descent-algorithm-for-the-lasso-problem">A Coordinate Descent Algorithm for the Lasso Problem (Chi)</a></li>
<li><a href="https://www.coursera.org/learn/ml-regression/lecture/6OLyn/deriving-the-lasso-coordinate-descent-update">Deriving the lasso coordinate descent update (Fox)</a></li>
</ul>
<h2 id="acknowledgements" tabindex="-1">Acknowledgements</h2>
<a class="dn" href="#acknowledgements"><span class="dn">Permalink to “Acknowledgements”</span> <span aria-hidden="true">#</span></a><p>Many thanks to Chris Xie and John Thickstun for helping me out with math. All errors are my own.</p>

      </div>

      
      

      
      
    </main>
  </div>

  
  <footer class="mt5 mb0">
    <div class="mt1 fade-bg pa4 pa5-l">
        <form style="" action="https://tinyletter.com/mbforbes" method="post" target="popupwindow"
            onsubmit="window.open('https://tinyletter.com/mbforbes', 'popupwindow', 'scrollbars=yes,width=800,height=600');return true">
            <p class="f6 fw6 ttu tracked mt0 mb4">
                Monthly digest
            </p>
            <p class="mb2 f6 fw6">
                <label for="tlemail">
                    I send a summary of my new posts each month.
                    Unsub whenever.
                </label>
            </p>
            <div class="mv1 w-100 w-50-l">
                <input class="input-reset mw-100 w-100 w5-ns ba b--black-20 pv3 ph3 ph4-ns f5" type="text" style="" name="email" id="tlemail" placeholder="Email"/>
                <input type="hidden" value="1" name="embed"/>
                <input class="input-reset mt1 mt0-ns w-100 w-auto-ns f5 pv2 pv3-ns ph4 emailButton pointer" style="" type="submit" value="Beep boop"/>
            </div>
            
        </form>
    </div>
  </footer>

  
  <script>
    // settings
    let periods = 0.5;
    let baseDelay = 1; // s
    let charDelay = 0.1; // s
    let duration = 0.70; // s
    let startW = 400; // w
    let mag = 400; // +/- w
    let refresh = 0.016667; // s

    // computed vals
    let frames = duration / refresh;

    // state
    let updaters = [];
    let frameNs = [];

    function fontWeighter(idx) {
      frameNs[idx] += 1;
      let x = (frameNs[idx] / frames) * periods * 2 * Math.PI;
      let w = Math.round(startW + mag * Math.sin(x));
      document
        .getElementById("header")
        .children[idx]
        .style
        .fontWeight = w;
      if (frameNs[idx] >= frames) {
        clearInterval(updaters[idx]);
      }
    }

    function wave() {
      // replace the string w/ elements. i write it as a string to start because i
      // couldn't get vscode's html formatter (using one for nunjucks) to not split
      // span elements each onto their own lines, which caused spaces between each
      // letter.
      let header = document.getElementById("header");
      let name = header.innerText;
      let els = [];
      for (let i = 0; i < name.length; i++) {
        let el = document.createElement("span");
        el.innerText = name[i];
        els.push(el);
      }
      header.innerText = '';
      header.append(...els);

      for (let i = 0; i < els.length; i++) {
        frameNs.push(0);
        setTimeout(() => {
          updaters.push(setInterval(fontWeighter.bind(null, i), refresh * 1000));
        }, (baseDelay + charDelay * i) * 1000);
      }
    }

    wave();
  </script>


    </body>

</html>
