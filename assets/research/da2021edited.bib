@inproceedings{da-etal-2021-edited,
    title = "Edited Media Understanding Frames: Reasoning About the Intent and Implications of Visual Misinformation",
    author = "Da, Jeff  and
      Forbes, Maxwell  and
      Zellers, Rowan  and
      Zheng, Anthony  and
      Hwang, Jena D.  and
      Bosselut, Antoine  and
      Choi, Yejin",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.158",
    doi = "10.18653/v1/2021.acl-long.158",
    pages = "2026--2039",
    abstract = "Understanding manipulated media, from automatically generated {`}deepfakes{'} to manually edited ones, raises novel research challenges. Because the vast majority of edited or manipulated images are benign, such as photoshopped images for visual enhancements, the key challenge is to understand the complex layers of underlying intents of media edits and their implications with respect to disinformation. In this paper, we study Edited Media Frames, a new formalism to understand visual media manipulation as structured annotations with respect to the intents, emotional reactions, attacks on individuals, and the overall implications of disinformation. We introduce a dataset for our task, EMU, with 56k question-answer pairs written in rich natural language. We evaluate a wide variety of vision-and-language models for our task, and introduce a new model PELICAN, which builds upon recent progress in pretrained multimodal representations. Our model obtains promising results on our dataset, with humans rating its answers as accurate 48.2{\%} of the time. At the same time, there is still much work to be done {--} and we provide analysis that highlights areas for further progress.",
}
